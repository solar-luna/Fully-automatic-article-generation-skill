#!/usr/bin/env python3
"""
æ›´æ–°å‘å¸ƒå†å²è®°å½•è„šæœ¬
å°†æœ¬æ¬¡ç”Ÿæˆçš„æ–‡ç« ä¿¡æ¯å†™å…¥å†å²æ•°æ®åº“ï¼Œå¹¶è‡ªåŠ¨æ¸…ç†è¿‡æœŸè®°å½•
"""

import json
import os
import sys
import time
import re
from datetime import datetime


def extract_keywords(topic):
    """ä»è¯é¢˜ä¸­æå–å…³é”®è¯é›†åˆ"""
    text = (topic.get('title', '') + ' ' + topic.get('summary', '')).lower()

    # ç§»é™¤åœç”¨è¯
    stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
                 'of', 'with', 'by', 'from', 'is', 'are', 'was', 'were',
                 'çš„', 'äº†', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†æ˜¯', 'åœ¨', 'ä¸º', 'ç”¨'}

    # åˆ†è¯ï¼ˆç®€å•çš„ç©ºæ ¼åˆ†å‰² + æ ‡ç‚¹ç¬¦å·å¤„ç†ï¼‰
    words = re.findall(r'\b\w+\b', text)

    # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
    keywords = {w for w in words if len(w) > 2 and w not in stopwords}

    return keywords


def update_history(topic, title, published=True):
    """
    æ›´æ–°å‘å¸ƒå†å²

    Args:
        topic: é€‰ä¸­çš„è¯é¢˜å­—å…¸
        title: ç”Ÿæˆçš„æ ‡é¢˜
        published: æ˜¯å¦å·²å‘å¸ƒ
    """
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    cache_dir = os.path.join(os.path.dirname(script_dir), 'cache')
    history_file = os.path.join(cache_dir, 'publish_history.json')

    # ç¡®ä¿cacheç›®å½•å­˜åœ¨
    os.makedirs(cache_dir, exist_ok=True)

    # åˆå§‹åŒ–æˆ–åŠ è½½å†å²æ–‡ä»¶
    if not os.path.exists(history_file):
        data = {'records': []}
        print(f"âœ… åˆ›å»ºæ–°çš„å†å²è®°å½•æ–‡ä»¶: {history_file}")
    else:
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if 'records' not in data:
                data = {'records': []}
        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸  å†å²è®°å½•æ–‡ä»¶æŸåï¼Œé‡æ–°åˆå§‹åŒ–: {e}")
            data = {'records': []}

    # æå–å…³é”®è¯
    keywords = list(extract_keywords(topic))

    # åˆ›å»ºæ–°è®°å½•
    record = {
        'date': datetime.now().strftime('%Y-%m-%d'),
        'time': datetime.now().strftime('%H:%M'),
        'timestamp': int(time.time()),
        'title': title,
        'url': topic.get('url', ''),
        'summary': topic.get('summary', ''),
        'content_type': topic.get('content_type', 'unknown'),
        'keywords': keywords,
        'published': published
    }

    # æ·»åŠ è®°å½•
    data['records'].append(record)
    print(f"âœ… æ·»åŠ è®°å½•: {title}")

    # è‡ªåŠ¨æ¸…ç†7å¤©å‰çš„è®°å½•
    cutoff = time.time() - (7 * 24 * 3600)
    original_count = len(data['records'])
    data['records'] = [r for r in data['records'] if r.get('timestamp', 0) > cutoff]
    cleaned_count = original_count - len(data['records'])

    if cleaned_count > 0:
        print(f"ğŸ§¹ æ¸…ç†äº† {cleaned_count} æ¡è¿‡æœŸè®°å½•ï¼ˆ>7å¤©ï¼‰")

    # ä¿å­˜
    try:
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å†å²è®°å½•å·²æ›´æ–°: {history_file}")
        print(f"ğŸ“Š å½“å‰å†å²è®°å½•æ€»æ•°: {len(data['records'])}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 3:
        print("ç”¨æ³•: update_history.py <selected_topic.json> <ç”Ÿæˆçš„æ ‡é¢˜>")
        print("ç¤ºä¾‹: update_history.py cache/selected_topic.json 'Claude 3.5æ¥äº†ï¼æé«˜æ•ˆç‡æ•ˆç‡æå‡3å€'")
        sys.exit(1)

    topic_file = sys.argv[1]
    title = sys.argv[2]

    # æ£€æŸ¥topicæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(topic_file):
        print(f"âŒ è¯é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {topic_file}")
        sys.exit(1)

    # è¯»å–è¯é¢˜
    try:
        with open(topic_file, 'r', encoding='utf-8') as f:
            topic = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–è¯é¢˜æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

    # æ›´æ–°å†å²
    update_history(topic, title)


if __name__ == '__main__':
    main()
